{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(100, 20, num_layers=4)\n",
      "torch.Size([10, 3, 20]) torch.Size([4, 3, 20])\n"
     ]
    }
   ],
   "source": [
    "rnn = nn.RNN(input_size=100, hidden_size=20, num_layers=4)\n",
    "print(rnn)\n",
    "x = torch.randn(10, 3, 100)  # [seq_len, batch_sz, feature_len]\n",
    "out, h = rnn(x, torch.zeros(4, 3, 20))  # shape of h_0 [layer_num, batch_sz, hidden_len]\n",
    "print(out.shape, h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(3, 2)\n",
      "torch.Size([4, 3, 2]) torch.Size([1, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "rnn = nn.RNN(input_size=3, hidden_size=2, num_layers=1)\n",
    "print(rnn)\n",
    "x = torch.randn(4, 3, 3)  # [seq_len, batch_sz, feature_len]\n",
    "out, h = rnn(x, torch.zeros(1, 3, 2))  # shape of h_0 [layer_num, batch_sz, hidden_len]\n",
    "print(out.shape, h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0726,  0.4869],\n",
       "         [-0.1524,  0.4313],\n",
       "         [-0.2947,  0.0938]],\n",
       "\n",
       "        [[ 0.0922,  0.2413],\n",
       "         [-0.4865,  0.1921],\n",
       "         [-0.7046,  0.3641]],\n",
       "\n",
       "        [[ 0.4198, -0.0274],\n",
       "         [-0.0031,  0.1791],\n",
       "         [-0.2733, -0.1712]],\n",
       "\n",
       "        [[-0.1749,  0.2819],\n",
       "         [-0.8739,  0.2964],\n",
       "         [-0.1505,  0.0395]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1749,  0.2819],\n",
       "         [-0.8739,  0.2964],\n",
       "         [-0.1505,  0.0395]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(3, 2, num_layers=5)\n",
      "torch.Size([4, 3, 2]) torch.Size([5, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "rnn = nn.RNN(input_size=3, hidden_size=2, num_layers=5)\n",
    "print(rnn)\n",
    "x = torch.randn(4, 3, 3)  # [seq_len, batch_sz, feature_len]\n",
    "out, h = rnn(x, torch.zeros(5, 3, 2))  # shape of h_0 [layer_num, batch_sz, hidden_len]\n",
    "print(out.shape, h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3873, -0.7097],\n",
       "         [ 0.3309, -0.7319],\n",
       "         [ 0.3273, -0.7330]],\n",
       "\n",
       "        [[ 0.0108, -0.6608],\n",
       "         [-0.0616, -0.6494],\n",
       "         [-0.0580, -0.6465]],\n",
       "\n",
       "        [[ 0.1291, -0.6409],\n",
       "         [ 0.2026, -0.5927],\n",
       "         [ 0.2053, -0.5925]],\n",
       "\n",
       "        [[ 0.0967, -0.6369],\n",
       "         [ 0.1388, -0.6558],\n",
       "         [ 0.0541, -0.6807]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4991,  0.6221],\n",
       "         [-0.8420, -0.1179],\n",
       "         [-0.0058,  0.9031]],\n",
       "\n",
       "        [[ 0.1406, -0.7093],\n",
       "         [ 0.7324, -0.4716],\n",
       "         [-0.2299, -0.8158]],\n",
       "\n",
       "        [[ 0.5474, -0.1849],\n",
       "         [ 0.3050, -0.1564],\n",
       "         [ 0.6258,  0.2289]],\n",
       "\n",
       "        [[ 0.5059, -0.5888],\n",
       "         [ 0.4571, -0.6981],\n",
       "         [ 0.5753, -0.5706]],\n",
       "\n",
       "        [[ 0.0967, -0.6369],\n",
       "         [ 0.1388, -0.6558],\n",
       "         [ 0.0541, -0.6807]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn by cell\n",
      "torch.Size([3, 20])\n",
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "print('rnn by cell')\n",
    "\n",
    "x = torch.randn(10, 3, 100)  # [seq_len, batch_sz, feature_len]\n",
    "cell1 = nn.RNNCell(100, 20)  # [feature_len, hidden_len]\n",
    "h1 = torch.zeros(3, 20)      # [batch_sz, hidden_len]\n",
    "for xt in x:\n",
    "    h1 = cell1(xt, h1)\n",
    "print(h1.shape)\n",
    "\n",
    "\n",
    "cell1 = nn.RNNCell(100, 30)\n",
    "cell2 = nn.RNNCell(30, 20)\n",
    "h1 = torch.zeros(3, 30)\n",
    "h2 = torch.zeros(3, 20)\n",
    "for xt in x:\n",
    "    h1 = cell1(xt, h1)\n",
    "    h2 = cell2(h1, h2)\n",
    "print(h2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(100, 20, num_layers=4)\n",
      "torch.Size([10, 3, 20]) torch.Size([4, 3, 20]) torch.Size([4, 3, 20])\n"
     ]
    }
   ],
   "source": [
    "lstm = nn.LSTM(input_size=100, hidden_size=20, num_layers=4)\n",
    "print(lstm)\n",
    "x = torch.randn(10, 3, 100)  # [seq_len, bz, feature_len]\n",
    "out, (h, c) = lstm(x)  # \n",
    "print(out.shape, h.shape, c.shape)  # [seq_len, bz, hidden_len], [layer_num, bz, hidden_len], \n",
    "                                    # [layer_num, bz, hidden_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(input_size=100, hidden_size=20, num_layers=4)\n",
    "print(lstm)\n",
    "x = torch.randn(10, 3, 100)  # [seq_len, bz, feature_len]\n",
    "out, (h, c) = lstm(x)  # \n",
    "print(out.shape, h.shape, c.shape)  # [seq_len, bz, hidden_len], [layer_num, bz, hidden_len], \n",
    "                                    # [layer_num, bz, hidden_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(3, 2, num_layers=5)\n",
      "torch.Size([4, 3, 2]) torch.Size([5, 3, 2]) torch.Size([5, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "lstm = nn.LSTM(input_size=3, hidden_size=2, num_layers=5)\n",
    "print(lstm)\n",
    "x = torch.randn(4, 3, 3)  # [seq_len, bz, feature_len]\n",
    "out, (h, c) = lstm(x)  # \n",
    "print(out.shape, h.shape, c.shape)  # [seq_len, bz, hidden_len], [layer_num, bz, hidden_len], \n",
    "                                    # [layer_num, bz, hidden_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0244, 0.1509],\n",
       "         [0.0244, 0.1509],\n",
       "         [0.0244, 0.1509]],\n",
       "\n",
       "        [[0.0505, 0.2394],\n",
       "         [0.0505, 0.2393],\n",
       "         [0.0505, 0.2394]],\n",
       "\n",
       "        [[0.0743, 0.2974],\n",
       "         [0.0743, 0.2974],\n",
       "         [0.0743, 0.2974]],\n",
       "\n",
       "        [[0.0945, 0.3382],\n",
       "         [0.0945, 0.3381],\n",
       "         [0.0945, 0.3382]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0907, -0.0365],\n",
       "         [-0.1266, -0.1164],\n",
       "         [-0.2623,  0.0528]],\n",
       "\n",
       "        [[ 0.0125, -0.1519],\n",
       "         [ 0.0184, -0.1204],\n",
       "         [ 0.0353, -0.1028]],\n",
       "\n",
       "        [[-0.3961,  0.6495],\n",
       "         [-0.3967,  0.6493],\n",
       "         [-0.3961,  0.6473]],\n",
       "\n",
       "        [[ 0.1129,  0.0822],\n",
       "         [ 0.1130,  0.0822],\n",
       "         [ 0.1132,  0.0823]],\n",
       "\n",
       "        [[ 0.0945,  0.3382],\n",
       "         [ 0.0945,  0.3381],\n",
       "         [ 0.0945,  0.3382]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2564, -0.0649],\n",
       "         [-0.2332, -0.8014],\n",
       "         [-0.3627,  0.1865]],\n",
       "\n",
       "        [[ 0.0387, -0.4104],\n",
       "         [ 0.0545, -0.3297],\n",
       "         [ 0.0975, -0.3081]],\n",
       "\n",
       "        [[-0.6566,  1.5493],\n",
       "         [-0.6554,  1.5406],\n",
       "         [-0.6528,  1.5326]],\n",
       "\n",
       "        [[ 0.1725,  0.1922],\n",
       "         [ 0.1728,  0.1921],\n",
       "         [ 0.1731,  0.1922]],\n",
       "\n",
       "        [[ 0.3026,  0.4658],\n",
       "         [ 0.3026,  0.4657],\n",
       "         [ 0.3026,  0.4657]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one layer lstm\n",
      "torch.Size([3, 20]) torch.Size([3, 20])\n",
      "two layer lstm\n",
      "torch.Size([3, 20]) torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10, 3, 100)  # [seq_len, batch_sz, feature_len]\n",
    "print('one layer lstm')\n",
    "cell = nn.LSTMCell(input_size=100, hidden_size=20)\n",
    "h = torch.zeros(3, 20)\n",
    "c = torch.zeros(3, 20)\n",
    "for xt in x:\n",
    "    h, c = cell(xt, [h, c])\n",
    "print(h.shape, c.shape)\n",
    "\n",
    "\n",
    "print('two layer lstm')\n",
    "cell1 = nn.LSTMCell(input_size=100, hidden_size=30)\n",
    "cell2 = nn.LSTMCell(input_size=30, hidden_size=20)\n",
    "h1 = torch.zeros(3, 30)\n",
    "c1 = torch.zeros(3, 30)\n",
    "h2 = torch.zeros(3, 20)\n",
    "c2 = torch.zeros(3, 20)\n",
    "for xt in x:\n",
    "    h1, c1 = cell1(xt, [h1, c1])\n",
    "    h2, c2 = cell2(h1, [h2, c2])\n",
    "print(h2.shape, c2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
